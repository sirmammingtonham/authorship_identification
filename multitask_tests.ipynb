{"cells":[{"cell_type":"markdown","metadata":{"id":"RJ_65wNsPmTL"},"source":["###setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27497,"status":"ok","timestamp":1665983627954,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"yn017AxxgF0i","outputId":"4dc35e79-0fe7-45a0-8be3-ed23f66710bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n","\u001b[K     |████████████████████████████████| 441 kB 6.7 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 59.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 63.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (5.0.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 57.2 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 64.3 MB/s \n","\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 78.0 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 34.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.9.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.6.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 tokenizers-0.13.1 transformers-4.23.1 urllib3-1.25.11 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/accelerate\n","  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-cvcbg7vd\n","  Running command git clone -q https://github.com/huggingface/accelerate /tmp/pip-req-build-cvcbg7vd\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate==0.14.0.dev0) (5.4.8)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.14.0.dev0) (1.12.1+cu113)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.14.0.dev0) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.14.0.dev0) (21.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate==0.14.0.dev0) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate==0.14.0.dev0) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate==0.14.0.dev0) (4.1.1)\n","Building wheels for collected packages: accelerate\n","  Building wheel for accelerate (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for accelerate: filename=accelerate-0.14.0.dev0-py3-none-any.whl size=164523 sha256=cc1563813549b5e4f35fde5d9a61ce02ec3836d99fafc9d83c048708365b0529\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dmuk2j35/wheels/81/c1/23/6068c1115888b4dd7da88f966c002c30840985c047f6cc1653\n","Successfully built accelerate\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.14.0.dev0\n"]}],"source":["!pip install datasets transformers\n","# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n","!pip install git+https://github.com/huggingface/accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1665983627955,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"lFRzYKOXj-Nn"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1854,"status":"ok","timestamp":1665983629797,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"8ZkKOaZSlz8e"},"outputs":[],"source":["%%capture\n","!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00217/C50.zip\n","!unzip C50"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665983629798,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"0Eczfy0S6Pqz"},"outputs":[],"source":["#@title hyperparams\n","model_checkpoint = \"roberta-base\" #@param {type:\"string\"}\n","max_length = 512 #@param {type:\"number\"}\n","learning_rate = 2e-5 #@param {type:\"number\"}\n","num_epochs = 100 #@param {type:\"number\"}\n","train_batch_size = 8 #@param {type:\"number\"}\n","eval_batch_size = 32 #@param {type:\"number\"}\n","valid_frac = 0.1 #@param {type:\"number\"}\n","seed = 42 #@param {type:\"number\"}\n","temperature = 0.7 #@param {type:\"number\"}\n","custom_split = -1 #@param {type:\"number\"}\n","fp16 = True #@param {type:\"boolean\"}\n","\n","hyperparameters = {\n","    \"learning_rate\": learning_rate,\n","    \"temperature\": temperature,\n","    \"num_epochs\": num_epochs,\n","    \"train_batch_size\": train_batch_size,\n","    \"eval_batch_size\": eval_batch_size,\n","    \"seed\": seed\n","}"]},{"cell_type":"markdown","metadata":{"id":"XIRPEwxx7cO8"},"source":["### code"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1665983630002,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"WblZO6XQ2tgH","outputId":"8c4514c9-e9a8-4ce2-e6a6-ceaccc9c7fe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 50 authors (both train and test), the first 3: [\"LynneO'Donnell\", 'AlanCrosby', 'KevinDrawbaugh']\n","There are 50 (train) articles written by the first author\n","There are 50 (test) articles written by the first author\n","The shape of train articles is (2500, 2)\n","The shape of test articles is (2500, 2)\n"]}],"source":["from os import listdir\n","from os.path import isfile, isdir, join\n","import numpy as np\n","\n","author_names = [name for name in listdir('C50train/') if isdir(join('C50train/', name))]\n","print('There are', len(author_names), 'authors (both train and test), the first 3:', author_names[:3])\n","\n","train_article_names = [[article_name for article_name in listdir('C50train/' + author_name + '/') if isfile(join('C50train/' + author_name + '/', article_name))]\n","                  for author_name in author_names]\n","print('There are', len(train_article_names[0]), '(train) articles written by the first author')\n","test_article_names = [[article_name for article_name in listdir('C50test/' + author_name + '/') if isfile(join('C50test/' + author_name + '/', article_name))]\n","                  for author_name in author_names]\n","print('There are', len(test_article_names[0]), '(test) articles written by the first author')\n","\n","train_articles = np.empty((2500, 2), dtype=object)\n","for i, author_name in enumerate(author_names):\n","  for j, article_name in enumerate(train_article_names[i]):\n","    file_path = 'C50train/' + author_name + '/' + article_name\n","    with open(file_path, 'r') as f:\n","      train_articles[i * len(author_names) + j, 0] = author_name\n","      train_articles[i * len(author_names) + j, 1] = f.read()\n","print('The shape of train articles is', train_articles.shape)\n","\n","test_articles = np.empty((2500, 2), dtype=object)\n","for i, author_name in enumerate(author_names):\n","  for j, article_name in enumerate(test_article_names[i]):\n","    file_path = 'C50test/' + author_name + '/' + article_name\n","    with open(file_path, 'r') as f:\n","      test_articles[i * len(author_names) + j, 0] = author_name\n","      test_articles[i * len(author_names) + j, 1] = f.read()\n","print('The shape of test articles is', test_articles.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":979,"status":"ok","timestamp":1665983630979,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"59dnbT92U5dw"},"outputs":[],"source":["# get the data in a format for the train script\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","\n","if custom_split > 0:\n","    total = pd.DataFrame(data=np.concatenate([train_articles, test_articles]), columns=['labels','anchor'])\n","\n","    train = total.sample(frac=.8, random_state=42)\n","    test = total.drop(train.index)\n","else:\n","    train = pd.DataFrame(data=train_articles, columns=['labels','anchor'])\n","    test = pd.DataFrame(data=test_articles, columns=['labels','anchor'])\n","\n","# train['replica'] = train.apply(lambda row: train[train['labels']==row['labels']].sample(1)['anchor'].item(), axis=1)\n","# test['replica'] = test.apply(lambda row: test[test['labels']==row['labels']].sample(1)['anchor'].item(), axis=1)\n","\n","train['labels'] = label_encoder.fit_transform(train['labels'])\n","\n","valid = train.sample(frac=valid_frac, random_state=hyperparameters[\"seed\"])\n","train = train.drop(valid.index)\n","\n","train.to_csv('/content/train.csv', index=False)\n","valid.to_csv('/content/valid.csv', index=False)\n","\n","test['labels'] = label_encoder.transform(test['labels'])\n","test.to_csv('/content/test.csv', index=False)\n","\n","del train\n","del valid\n","del test"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["ff481ba5d758489499e418c8cd2f038c","23dd51eb8b194f14bf5a4f7d4bda35de","1bbf68f12c5741859dee7005d178c28b","f425e38d70cf4b678e706e7b030083f5","c3f4c81aea294a239b80f4bee7303b86","80f3aa786b314e4882cc5b2bdde18a8f","3e43b7dca60a40f8827ad81a77a50a68","d2d9fe0be1164fff981cf2601bb5e52e","9c9d70e50d73494192ed54245597ad30","c6db41d301004e958f2fea19ccaa6998","ae0eecec70e846078741ae08c0734a99","0027ebdb9cc34ac6b6631a0a999d6e84","ee93a1a725b64b78944095611d702f03","3d3ff0016f2945d6bf83c1832129c0e0","5fb597f2a0954a418fb773679924d0eb","4fe7096ced1749b284b038c84dbe5445","7cf2d72aa1934d73ad56cf51ebd68775","727eb72f6d1147bdb89b9a40e4fc8669","5520f2d2d4274899bf5d449244367def","a514f36fcd6f4c1eba1cccb6fbc862f4","288c915b973044f2adcabca9f8f941e6","4610947c0a0540fb841e4e239e2861f4","eeaee1609c854a5db3192e8581b00942","cefcbb2fcc8a4630ad3b10e4dce6c42a","ed7a7fb70f4640f8ba92b8dc89044277","71e3b6c78cac498387bccccf5b23218e","c58f442662e34ec0adeb14d4c2710b82","094535441b964786bed4860ab309a4be","9a9f1f1f5f6f4068920dfda2db01c097","454091026cbe48ef81e57ebd0c3012b5","e2e6d1e10fb34daea60ef72f995ff880","be32063f485f44b89f4d0fe873bda711","43e85aca7957440bb0a23004949cf980","73d088cd4c0f4cd285b793d6b3cafabd","552ac2acad8b4c08ae9cfdbf8ee82c1e","74c3f2eaaa0942669baa07d3e86ba1d4","96c978bef8c8444cb943d3964b352576","1b46434bcdb640e18b840253b060d028","5cc511d55e534abb987005861fab0fb3","8cbb326c1eca49f3a69043381201e183","9c9f4490eed142c3abd97cf773ed2e1d","4406d252e3b34f83b66f0646ae4f1cd2","ebbe135349954ca4a5b6c22964a3289e","4f5a81d328cb48d4bbecf02bd406da82"]},"executionInfo":{"elapsed":5661,"status":"ok","timestamp":1665983636637,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"f5P9G3_CJ3s5","outputId":"770df1ff-c7df-4d34-cbbc-6cb4707ffacb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff481ba5d758489499e418c8cd2f038c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0027ebdb9cc34ac6b6631a0a999d6e84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeaee1609c854a5db3192e8581b00942"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73d088cd4c0f4cd285b793d6b3cafabd"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9973,"status":"ok","timestamp":1665983646601,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"5HTSlXqpgMfE"},"outputs":[],"source":["# adapted from https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_nlp_example.ipynb\n","import torch\n","from torch.utils.data import DataLoader\n","\n","from accelerate import Accelerator, DistributedType\n","from datasets import load_dataset, load_metric\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    get_linear_schedule_with_warmup,\n","    set_seed,\n",")\n","\n","from tqdm.auto import tqdm\n","\n","import datasets\n","import transformers"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from transformers import AutoModel\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","class DynamicLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size=100,\n","                    num_layers=1, dropout=0., bidirectional=False):\n","        super(DynamicLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.lstm = torch.nn.LSTM(\n","            input_size, self.hidden_size, num_layers, bias=True,\n","            batch_first=True, dropout=dropout, bidirectional=bidirectional)\n","        \n","    def forward(self, x, attention_mask=None):\n","        if attention_mask is None:\n","            attention_mask = torch.ones(x.shape[:-1])\n","\n","        seq_lens = attention_mask.sum(-1)\n","        batch_size = attention_mask.shape[0]\n","        seq_len = attention_mask.shape[1]\n","\n","        # sort input by descending length\n","        _, idx_sort = torch.sort(seq_lens, dim=0, descending=True)\n","        _, idx_unsort = torch.sort(idx_sort, dim=0)\n","        x_sort = torch.index_select(x, dim=0, index=idx_sort)\n","        seq_lens_sort = torch.index_select(seq_lens, dim=0, index=idx_sort)\n","\n","        # pack input\n","        x_packed = pack_padded_sequence(\n","            x_sort, seq_lens_sort.cpu(), batch_first=True)\n","\n","        # pass through rnn\n","        y_packed, _ = self.lstm(x_packed)\n","\n","        # unpack output\n","        y_sort, length = pad_packed_sequence(y_packed, batch_first=True)\n","\n","        # unsort output to original order\n","        y = torch.index_select(y_sort, dim=0, index=idx_unsort)\n","\n","        batch_indices = torch.arange(0, batch_size)\n","        seq_indices = seq_lens - 1\n","\n","        y_split = y.view(batch_size, seq_len, 2, self.hidden_size)\n","\n","        output = torch.cat(\n","            [y_split[batch_indices, seq_indices, 0], y_split[batch_indices, 0, 1]], dim=-1)\n","\n","        return output"],"metadata":{"id":"Nsz1SFRrkyuF","executionInfo":{"status":"ok","timestamp":1665983646601,"user_tz":240,"elapsed":23,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class EmbeddingModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.transformer = AutoModel.from_pretrained(model_checkpoint)\n","        config = self.transformer.config\n","        embed_size = self.transformer.config.hidden_size//2\n","        self.pooler = DynamicLSTM(self.transformer.config.hidden_size,\n","                                  embed_size,\n","                                  dropout=.1,\n","                                  bidirectional=True)\n","        self.temperature = torch.nn.Parameter(torch.Tensor([hyperparameters[\"temperature\"]]))\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        outputs = self.transformer(input_ids, attention_mask, token_type_ids, return_dict=True)\n","\n","        embedding = outputs.last_hidden_state\n","\n","        embedding = self.pooler(embedding, attention_mask)\n","\n","        return F.normalize(embedding)\n","\n","class ContrastiveModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.transformer = AutoModel.from_pretrained(model_checkpoint)\n","        config = self.transformer.config\n","        self.embed_dropout = nn.Dropout(config.hidden_dropout_prob)\n","        # self.cls_dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.embed_projection = nn.Linear(config.hidden_size, config.hidden_size//2)\n","        self.flatten = nn.Flatten()\n","        self.classifier = nn.Linear(config.hidden_size//2*max_length, 50)\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        outputs = self.transformer(input_ids, attention_mask, token_type_ids, return_dict=True)\n","\n","        embedding = outputs.last_hidden_state\n","        # embedding = self.embed_dropout(embedding)\n","        embedding = self.embed_projection(embedding)\n","        embedding = self.flatten(embedding)\n","\n","        logits = self.activation(embedding)\n","        # logits = self.cls_dropout(logits)\n","        logits = self.classifier(logits)\n","\n","        return embedding, logits\n","\n","class EmbeddingClassificationModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.transformer = AutoModel.from_pretrained(model_checkpoint)\n","        config = self.transformer.config\n","        embed_size = self.transformer.config.hidden_size//2\n","        self.pooler = DynamicLSTM(self.transformer.config.hidden_size,\n","                                  embed_size,\n","                                  dropout=.1,\n","                                  bidirectional=True)\n","        self.temperature = torch.nn.Parameter(torch.Tensor([hyperparameters[\"temperature\"]]))\n","        self.cls_dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(self.transformer.config.hidden_size, 50)\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        outputs = self.transformer(input_ids, attention_mask, token_type_ids, return_dict=True)\n","\n","        embedding = outputs.last_hidden_state\n","\n","        embedding = self.pooler(embedding, attention_mask)\n","        embedding = F.normalize(embedding)\n","        logits = self.activation(embedding)\n","        logits = self.cls_dropout(logits)\n","        logits = self.classifier(logits)\n","\n","        return embedding, logits"],"metadata":{"id":"hrwYA0j6k9va","executionInfo":{"status":"ok","timestamp":1665983646602,"user_tz":240,"elapsed":22,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["d99499198a44499eb6549216807d9aaf","fe1f0f11decc428cb5b38ed5fb17f194","97268edb88d84c4f93268ff7fa7bb857","8b42527ee51448d887c05eb0d17ead60","174e61c69b82448d9dd70c068f186e17","6b1879047cea456ab42fbc93a3c6866e","873720057bc7476cae88372c72c058ed","64a8ce93220e4910ae7bbb633f635b1d","f532932f2b0146c2816a4bd7ca78dedb","0616c64aa21d490ea4947208ffc11512","090a00d5ac4d463f80d2be8b0fa5634c"]},"executionInfo":{"elapsed":13874,"status":"ok","timestamp":1665983660454,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"S0SIXD2MTRdF","outputId":"61acae7a-a65f-4c02-f81c-9d674fca2386"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99499198a44499eb6549216807d9aaf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}],"source":["model = EmbeddingClassificationModel()"]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","class ContrastiveDataset(Dataset):\n","    def __init__(self, filename):\n","        self.df = pd.read_csv(filename)\n","        def transform(row):\n","            tokenized = tokenizer(row[\"anchor\"], truncation=True, padding=\"max_length\", max_length=max_length, return_tensors='pt')\n","            row['input_ids'] = tokenized['input_ids']\n","            row['attention_mask'] = tokenized['attention_mask']\n","            return row\n","\n","        self.df = self.df.apply(transform, axis=1)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        data = self.df.iloc[idx]\n","        label = data['labels']\n","        anchor = {'input_ids': data['input_ids'][0], 'attention_mask': data['attention_mask'][0]}\n","        replica = self.df[self.df['labels'] == label].sample(1)\n","        replica = {'input_ids': replica['input_ids'].item()[0], 'attention_mask': replica['attention_mask'].item()[0]}\n","        return label, anchor, replica"],"metadata":{"id":"GqWcNLZHoQ3S","executionInfo":{"status":"ok","timestamp":1665983660455,"user_tz":240,"elapsed":9,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665983660455,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"v6xVdz3nglnu"},"outputs":[],"source":["# raw_datasets = load_dataset(\n","#     \"csv\",\n","#     data_files={'train': 'train.csv', 'validation': 'valid.csv',  'test': 'test.csv'}\n","# )"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665983660457,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"uewpw_Fsg32D"},"outputs":[],"source":["# from transformers import AutoTokenizer\n","\n","# def tokenize_function(example):\n","    # return tokenizer(example[\"anchor\"], truncation=True, padding=\"max_length\", max_length=max_length)\n","    # return {\n","    #     \"anchor\": tokenizer(example[\"anchor\"], truncation=True, padding=\"max_length\", max_length=max_length), \n","    #     \"replica\": tokenizer(example[\"replica\"], truncation=True, padding=\"max_length\", max_length=max_length)\n","    # }\n","\n","# tokenize_function = lambda ex: tokenizer(ex[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n","# tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","# tokenized_datasets.set_format(\"torch\")\n","# tokenized_datasets[\"train\"].features"]},{"cell_type":"code","source":["# temp = ContrastiveDataset('train.csv').df\n","# candidates = []\n","# for i in temp['labels'].sort_values().unique():\n","#     replica = temp[temp['labels'] == i].sample(1)\n","#     candidates.append({\n","#         'input_ids':replica['input_ids'].item()[0], 'attention_mask': replica['attention_mask'].item()[0]\n","#     })\n","# candidates = np.array(candidates)\n","# del temp"],"metadata":{"id":"Y3Sr276z81wD","executionInfo":{"status":"ok","timestamp":1665983660655,"user_tz":240,"elapsed":18,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1665983660656,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"bT49Sd7_hy8K"},"outputs":[],"source":["def create_dataloaders(train_batch_size=16, eval_batch_size=32):\n","    train_dataloader = DataLoader(\n","        ContrastiveDataset(\"train.csv\"), shuffle=True, batch_size=train_batch_size\n","    )\n","    eval_dataloader = DataLoader(\n","        ContrastiveDataset(\"valid.csv\"), shuffle=False, batch_size=eval_batch_size\n","    )\n","    test_dataloader = DataLoader(\n","        ContrastiveDataset(\"test.csv\"), shuffle=False, batch_size=eval_batch_size\n","    )\n","    # train_dataloader = DataLoader(\n","    #     tokenized_datasets[\"train\"], shuffle=True, batch_size=train_batch_size\n","    # )\n","    # eval_dataloader = DataLoader(\n","    #     tokenized_datasets[\"validation\"], shuffle=False, batch_size=eval_batch_size\n","    # )\n","    # test_dataloader = DataLoader(\n","    #     tokenized_datasets[\"test\"], shuffle=False, batch_size=eval_batch_size\n","    # )\n","    return train_dataloader, eval_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["eae3a20aca844cd68ce455e7386731f5","e5f74bab89b94910a2122bf2dd6e1011","0e47da26353644d1b33497f8dc1a851d","8488098f91e44fbf837393f62f27b2c4","cc792a547b3f48258a080e8b98dd467c","7bb2bed077fb4d54a0f2186eb6c009d8","9d36919a47314b3795eadb7bb41345df","76f8c7c755e5431db56ab4cd1010caef","232777434a784470ab45c155429da15e","6ec5109d5e334068b29f8238c2265a7a","3b12a6789fc4473fa588231f68e64bad","e553dee82c314ecb902c83b6fdcb5320","8ffbd5847fde4074bb592094209c86d2","d52d5a4f08a24129b538257138abe308","141aed2685dd4e93859b5ed0e76809bc","ddfb8523f8164a60b9c6b6168f40fdbb","52a93cc120214b56b293ba11630bf62e","4e15e9c24b8344eea8c645f5d4e1e74b","fd6a2b6fe8f149a5b581b517d607dd0d","e7dc9477be5d45bc8b90ae32f682835c","ae085eae263c45cbb1ff49c3c126ef56","c09ef62f9d36468ca62b592592783e01"]},"executionInfo":{"elapsed":1022,"status":"ok","timestamp":1665983661659,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"WgAZAH6NiDtr","outputId":"88395281-0891-4da4-f8ae-e46a65833bc4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae3a20aca844cd68ce455e7386731f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e553dee82c314ecb902c83b6fdcb5320"}},"metadata":{}}],"source":["accuracy_metric = load_metric(\"accuracy\")\n","f1_metric = load_metric(\"f1\")"]},{"cell_type":"code","source":["def training_function(model):\n","    # Initialize accelerator\n","    accelerator = Accelerator()#log_with=\"all\", logging_dir=\"logs\")\n","    # accelerator.free_memory()\n","\n","    def infonce_loss(a, b, temp):\n","        batch_size = a.shape[0]\n","        logits = (a @ b.T) * torch.exp(temp).clamp(max=100)\n","        labels = torch.arange(0, batch_size, device=accelerator.device)\n","\n","        loss = (F.cross_entropy(logits.T, labels).mean() +\n","                F.cross_entropy(logits, labels).mean()) / 2\n","        \n","        with torch.no_grad():\n","            preds = F.softmax(logits, dim=1).argmax(-1)\n","            preds_t = F.softmax(logits.T, dim=1).argmax(-1)\n","\n","            accuracy = (torch.sum(preds == labels) +\n","                        torch.sum(preds_t == labels)) / (batch_size * 2)\n","\n","        return loss, accuracy\n","\n","\n","    if accelerator.is_main_process:\n","        datasets.utils.logging.set_verbosity_warning()\n","        transformers.utils.logging.set_verbosity_info()\n","    else:\n","        datasets.utils.logging.set_verbosity_error()\n","        transformers.utils.logging.set_verbosity_error()\n","    \n","    train_dataloader, eval_dataloader, test_dataloader = create_dataloaders(\n","        train_batch_size=hyperparameters[\"train_batch_size\"], eval_batch_size=hyperparameters[\"eval_batch_size\"]\n","    )\n","    set_seed(hyperparameters[\"seed\"])\n","    optimizer = torch.optim.AdamW(params=model.parameters(), lr=hyperparameters[\"learning_rate\"])\n","    # candidates = np.array(candidates)\n","\n","    model, optimizer, train_dataloader, eval_dataloader, test_dataloader, infonce_loss = accelerator.prepare(\n","        model, optimizer, train_dataloader, eval_dataloader, test_dataloader, infonce_loss\n","    )\n","\n","    num_epochs = hyperparameters[\"num_epochs\"]\n","\n","    lr_scheduler = get_linear_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=100,\n","        num_training_steps=len(train_dataloader) * num_epochs,\n","    )\n","\n","    # Instantiate a progress bar to keep track of training. Note that we only enable it on the main\n","    # process to avoid having 8 progress bars.\n","    progress_bar = tqdm(range(num_epochs * len(train_dataloader)), disable=not accelerator.is_main_process)\n","    # Now we train the model\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_contrastive_loss = 0\n","        total_classification_loss = 0\n","        for step, batch in enumerate(train_dataloader):\n","            labels, anchor, replica = batch\n","            # embed_anchor = model(**anchor)\n","            # embed_replica = model(**replica)\n","            embed_anchor, logits_anchor = model(**anchor)\n","            embed_replica, _ = model(**replica)\n","\n","            contrastive_loss, acc = infonce_loss(embed_anchor, embed_replica, model.temperature)\n","            classification_loss = torch.nn.functional.cross_entropy(logits_anchor.view(-1, 50), labels.view(-1))\n","            loss = torch.mean(contrastive_loss + classification_loss)\n","            accelerator.backward(loss)\n","\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","            progress_bar.update(1)\n","\n","        model.eval()\n","\n","        # with torch.no_grad():\n","        #     cc = [model(**{k: v.to(accelerator.device).unsqueeze(0) for k,v in candidate.items()}) for candidate in candidates]\n","        #     candidate_embeddings = torch.stack(cc)\n","        # for step, batch in enumerate(eval_dataloader):\n","        #     labels, anchor, replica = batch\n","        #     with torch.no_grad():\n","        #         embed_anchor = model(**anchor)\n","        #         # embed_replica, _ = model(**replica)\n","        #     sims = F.cosine_similarity(embed_anchor, candidate_embeddings.unsqueeze(1), dim=-1)\n","        #     predictions = sims.argmax(dim=0).squeeze(0)\n","        for step, batch in enumerate(eval_dataloader):\n","            labels, anchor, replica = batch\n","            with torch.no_grad():\n","                embed_anchor, logits_anchor = model(**anchor)\n","                # embed_replica, _ = model(**replica)\n","            predictions = logits_anchor.argmax(dim=-1)\n","            \n","            predictions, references = accelerator.gather_for_metrics((predictions, labels))\n","            accuracy_metric.add_batch(\n","                predictions=predictions,\n","                references=references,\n","            )\n","            f1_metric.add_batch(\n","                predictions=predictions,\n","                references=references,\n","            )\n","        accuracy_score = accuracy_metric.compute()\n","        f1_score = f1_metric.compute(average='micro')\n","\n","        # accelerator.log(\n","        #         {\n","        #         \"accuracy\": accuracy_score[\"accuracy\"],\n","        #         \"f1\": f1_score[\"f1\"],\n","        #         \"train_contrastive_loss\": total_contrastive_loss.item() / len(train_dataloader),\n","        #         \"train_classification_loss\": total_classification_loss.item() / len(train_dataloader),\n","        #         \"epoch\": epoch,\n","        #         },\n","        #         step=epoch,\n","        #     )\n","\n","        # Use accelerator.print to print only on the main process.\n","        accelerator.print(f\"epoch {epoch}, validation metrics:\", accuracy_score, f1_score)\n","\n","    # accelerator.end_training()\n","    ########## run test eval\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","\n","    for step, batch in enumerate(test_dataloader):\n","        labels, anchor, replica = batch\n","        with torch.no_grad():\n","            embed_anchor, logits_anchor = model(**anchor)\n","            # embed_replica, _ = model(**replica)\n","        predictions = logits_anchor.argmax(dim=-1)\n","\n","        predictions, references = accelerator.gather_for_metrics((predictions, labels))\n","        accuracy_metric.add_batch(\n","            predictions=predictions,\n","            references=references,\n","        )\n","        f1_metric.add_batch(\n","            predictions=predictions,\n","            references=references,\n","        )\n","    accuracy_score = accuracy_metric.compute()\n","    f1_score = f1_metric.compute(average='micro')\n","\n","    accelerator.print(f\"epoch {epoch}, test metrics:\", accuracy_score, f1_score)"],"metadata":{"id":"NYzszJ44mF4J","executionInfo":{"status":"ok","timestamp":1665983661660,"user_tz":240,"elapsed":4,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPYvBJ_Y7fWR"},"source":["### run training"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457,"referenced_widgets":["87983496340a4dc59a57c384bc3e84eb","755f025545c84fd497976b3b5d1d2551","8bba6f085f1242ab876670a65b8f2781","100f6004ea884232ab8f7f106742b4c5","4245f2e72d17432bab955b160d786d37","58d6d274571b47ef9f6f7672e05d9a94","5222919efae84f32a338671bdaa823aa","99de7d09885a460a8a0c6d8f73d2c7fc","b1424c7421a94835ad9747a994785a0b","686c86ff6595452780b0e0b3e26966ad","c6bd8db4813745d7b6467eab907ac751"]},"id":"LwmbD7RRkqtV","executionInfo":{"status":"error","timestamp":1665985661253,"user_tz":240,"elapsed":1999451,"user":{"displayName":"yeeb","userId":"09671650123333902832"}},"outputId":"185d178d-b964-4891-b6d8-8fc60cae5b62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Launching training on one GPU.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/28200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87983496340a4dc59a57c384bc3e84eb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 0, validation metrics: {'accuracy': 0.256} {'f1': 0.256}\n","epoch 1, validation metrics: {'accuracy': 0.264} {'f1': 0.264}\n","epoch 2, validation metrics: {'accuracy': 0.284} {'f1': 0.284}\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-154ee529f21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotebook_launcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnotebook_launcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/accelerate/launchers.py\u001b[0m in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, use_fp16, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Launching training on one CPU.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-987841c206ed>\u001b[0m in \u001b[0;36mtraining_function\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# embed_anchor = model(**anchor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# embed_replica = model(**replica)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0membed_anchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_anchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0membed_replica\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mreplica\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-2b2bda848b1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-4709b424ae86>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mseq_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_lens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0my_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         output = torch.cat(\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 512, 2, 384]' is invalid for input of size 783360"]}],"source":["from accelerate import notebook_launcher\n","\n","notebook_launcher(training_function, (model,))"]},{"cell_type":"code","source":["2*512*2*384"],"metadata":{"id":"H1Z1TEisfE-v","executionInfo":{"status":"ok","timestamp":1665985702534,"user_tz":240,"elapsed":5,"user":{"displayName":"yeeb","userId":"09671650123333902832"}},"outputId":"ff4175c7-2e51-4a6d-c610-e7160f96e8a7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["786432"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkWAJaijsbl1","executionInfo":{"status":"aborted","timestamp":1665985661255,"user_tz":240,"elapsed":12,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"outputs":[],"source":["# import gc\n","# del model\n","# gc.collect()\n","# model = ContrastiveModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1665985661262,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"4NCtrVyfgrXi"},"outputs":[],"source":["%tensorboard --logdir logs"]},{"cell_type":"code","source":[],"metadata":{"id":"0wFB6EBfmHuR","executionInfo":{"status":"aborted","timestamp":1665985661263,"user_tz":240,"elapsed":19,"user":{"displayName":"yeeb","userId":"09671650123333902832"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1665985661263,"user":{"displayName":"yeeb","userId":"09671650123333902832"},"user_tz":240},"id":"4bP5e4JGkSnb"},"outputs":[],"source":["def training_function(model):\n","    # Initialize accelerator\n","    accelerator = Accelerator()#log_with=\"all\", logging_dir=\"logs\")\n","    # accelerator.free_memory()\n","\n","    # temperature = torch.tensor(hyperparameters[\"temperature\"], device=accelerator.device)\n","    def infonce_loss(a, b, temp):\n","        batch_size = a.shape[0]\n","        logits = (a @ b.T) * torch.exp(temp).clamp(max=100)\n","        labels = torch.arange(0, batch_size, device=accelerator.device)\n","\n","        loss = (F.cross_entropy(logits.T, labels).mean() +\n","                F.cross_entropy(logits, labels).mean()) / 2\n","        \n","        with torch.no_grad():\n","            preds = F.softmax(logits, dim=1).argmax(-1)\n","            preds_t = F.softmax(logits.T, dim=1).argmax(-1)\n","\n","            accuracy = (torch.sum(preds == labels) +\n","                        torch.sum(preds_t == labels)) / (batch_size * 2)\n","\n","        return loss, accuracy\n","\n","\n","    if accelerator.is_main_process:\n","        datasets.utils.logging.set_verbosity_warning()\n","        transformers.utils.logging.set_verbosity_info()\n","    else:\n","        datasets.utils.logging.set_verbosity_error()\n","        transformers.utils.logging.set_verbosity_error()\n","\n","\n","    \n","    train_dataloader, eval_dataloader, test_dataloader = create_dataloaders(\n","        train_batch_size=hyperparameters[\"train_batch_size\"], eval_batch_size=hyperparameters[\"eval_batch_size\"]\n","    )\n","    set_seed(hyperparameters[\"seed\"])\n","    optimizer = torch.optim.AdamW(params=model.parameters(), lr=hyperparameters[\"learning_rate\"])\n","\n","    model, optimizer, train_dataloader, eval_dataloader, test_dataloader, infonce_loss = accelerator.prepare(\n","        model, optimizer, train_dataloader, eval_dataloader, test_dataloader, infonce_loss\n","    )\n","\n","    num_epochs = hyperparameters[\"num_epochs\"]\n","\n","    lr_scheduler = get_linear_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=100,\n","        num_training_steps=len(train_dataloader) * num_epochs,\n","    )\n","\n","    # Instantiate a progress bar to keep track of training. Note that we only enable it on the main\n","    # process to avoid having 8 progress bars.\n","    progress_bar = tqdm(range(num_epochs * len(train_dataloader)), disable=not accelerator.is_main_process)\n","    # Now we train the model\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_contrastive_loss = 0\n","        total_classification_loss = 0\n","        for step, batch in enumerate(train_dataloader):\n","            labels, anchor, replica = batch['labels'], batch['anchor'], batch['replica']\n","            embed_anchor, logits_anchor = model(**anchor)\n","            embed_replica, _ = model(**replica)\n","\n","            contrastive_loss = infonce_loss(embed_anchor, embed_replica, model.temperature)\n","            classification_loss = torch.nn.functional.cross_entropy(logits_anchor.view(-1, 50), labels.view(-1))\n","            loss = torch.mean(contrastive_loss + classification_loss)\n","            \n","\n","            accelerator.backward(loss)\n","\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","            progress_bar.update(1)\n","            total_contrastive_loss += contrastive_loss.detach().float()\n","            total_classification_loss += classification_loss.detach().float()\n","\n","        model.eval()\n","\n","        for step, batch in enumerate(eval_dataloader):\n","            labels, anchor, replica = batch['labels'], batch['anchor'], batch['replica']\n","            with torch.no_grad():\n","                embed_anchor, logits_anchor = model(**anchor)\n","                embed_replica, _ = model(**replica)\n","            predictions = logits_anchor.argmax(dim=-1)\n","\n","            predictions, references = accelerator.gather_for_metrics((predictions, batch[\"labels\"]))\n","            accuracy_metric.add_batch(\n","                predictions=predictions,\n","                references=references,\n","            )\n","            f1_metric.add_batch(\n","                predictions=predictions,\n","                references=references,\n","            )\n","        accuracy_score = accuracy_metric.compute()\n","        f1_score = f1_metric.compute(average='micro')\n","\n","        # accelerator.log(\n","        #         {\n","        #         \"accuracy\": accuracy_score[\"accuracy\"],\n","        #         \"f1\": f1_score[\"f1\"],\n","        #         \"train_contrastive_loss\": total_contrastive_loss.item() / len(train_dataloader),\n","        #         \"train_classification_loss\": total_classification_loss.item() / len(train_dataloader),\n","        #         \"epoch\": epoch,\n","        #         },\n","        #         step=epoch,\n","        #     )\n","\n","        # Use accelerator.print to print only on the main process.\n","        accelerator.print(f\"epoch {epoch}, validation metrics:\", accuracy_score, f1_score)\n","\n","    # accelerator.end_training()\n","    ########## run test eval\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","\n","    for step, batch in enumerate(test_dataloader):\n","        labels, anchor, replica = batch['labels'], batch['anchor'], batch['replica']\n","        with torch.no_grad():\n","            embed_anchor, logits_anchor = model(**anchor)\n","            embed_replica, _ = model(**replica)\n","        predictions = logits_anchor.argmax(dim=-1)\n","\n","        predictions, references = accelerator.gather_for_metrics((predictions, batch[\"labels\"]))\n","        accuracy_metric.add_batch(\n","            predictions=predictions,\n","            references=references,\n","        )\n","        f1_metric.add_batch(\n","            predictions=predictions,\n","            references=references,\n","        )\n","    accuracy_score = accuracy_metric.compute()\n","    f1_score = f1_metric.compute(average='micro')\n","\n","    accelerator.print(f\"epoch {epoch}, test metrics:\", accuracy_score, f1_score)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpMB1vmHn+XcCsx5jm6QQE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ff481ba5d758489499e418c8cd2f038c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23dd51eb8b194f14bf5a4f7d4bda35de","IPY_MODEL_1bbf68f12c5741859dee7005d178c28b","IPY_MODEL_f425e38d70cf4b678e706e7b030083f5"],"layout":"IPY_MODEL_c3f4c81aea294a239b80f4bee7303b86"}},"23dd51eb8b194f14bf5a4f7d4bda35de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80f3aa786b314e4882cc5b2bdde18a8f","placeholder":"​","style":"IPY_MODEL_3e43b7dca60a40f8827ad81a77a50a68","value":"Downloading: 100%"}},"1bbf68f12c5741859dee7005d178c28b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2d9fe0be1164fff981cf2601bb5e52e","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c9d70e50d73494192ed54245597ad30","value":481}},"f425e38d70cf4b678e706e7b030083f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6db41d301004e958f2fea19ccaa6998","placeholder":"​","style":"IPY_MODEL_ae0eecec70e846078741ae08c0734a99","value":" 481/481 [00:00&lt;00:00, 15.1kB/s]"}},"c3f4c81aea294a239b80f4bee7303b86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f3aa786b314e4882cc5b2bdde18a8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e43b7dca60a40f8827ad81a77a50a68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2d9fe0be1164fff981cf2601bb5e52e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c9d70e50d73494192ed54245597ad30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6db41d301004e958f2fea19ccaa6998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0eecec70e846078741ae08c0734a99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0027ebdb9cc34ac6b6631a0a999d6e84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee93a1a725b64b78944095611d702f03","IPY_MODEL_3d3ff0016f2945d6bf83c1832129c0e0","IPY_MODEL_5fb597f2a0954a418fb773679924d0eb"],"layout":"IPY_MODEL_4fe7096ced1749b284b038c84dbe5445"}},"ee93a1a725b64b78944095611d702f03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cf2d72aa1934d73ad56cf51ebd68775","placeholder":"​","style":"IPY_MODEL_727eb72f6d1147bdb89b9a40e4fc8669","value":"Downloading: 100%"}},"3d3ff0016f2945d6bf83c1832129c0e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5520f2d2d4274899bf5d449244367def","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a514f36fcd6f4c1eba1cccb6fbc862f4","value":898823}},"5fb597f2a0954a418fb773679924d0eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_288c915b973044f2adcabca9f8f941e6","placeholder":"​","style":"IPY_MODEL_4610947c0a0540fb841e4e239e2861f4","value":" 899k/899k [00:00&lt;00:00, 1.85MB/s]"}},"4fe7096ced1749b284b038c84dbe5445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cf2d72aa1934d73ad56cf51ebd68775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727eb72f6d1147bdb89b9a40e4fc8669":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5520f2d2d4274899bf5d449244367def":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a514f36fcd6f4c1eba1cccb6fbc862f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"288c915b973044f2adcabca9f8f941e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4610947c0a0540fb841e4e239e2861f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eeaee1609c854a5db3192e8581b00942":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cefcbb2fcc8a4630ad3b10e4dce6c42a","IPY_MODEL_ed7a7fb70f4640f8ba92b8dc89044277","IPY_MODEL_71e3b6c78cac498387bccccf5b23218e"],"layout":"IPY_MODEL_c58f442662e34ec0adeb14d4c2710b82"}},"cefcbb2fcc8a4630ad3b10e4dce6c42a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_094535441b964786bed4860ab309a4be","placeholder":"​","style":"IPY_MODEL_9a9f1f1f5f6f4068920dfda2db01c097","value":"Downloading: 100%"}},"ed7a7fb70f4640f8ba92b8dc89044277":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_454091026cbe48ef81e57ebd0c3012b5","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2e6d1e10fb34daea60ef72f995ff880","value":456318}},"71e3b6c78cac498387bccccf5b23218e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be32063f485f44b89f4d0fe873bda711","placeholder":"​","style":"IPY_MODEL_43e85aca7957440bb0a23004949cf980","value":" 456k/456k [00:00&lt;00:00, 1.31MB/s]"}},"c58f442662e34ec0adeb14d4c2710b82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094535441b964786bed4860ab309a4be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a9f1f1f5f6f4068920dfda2db01c097":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"454091026cbe48ef81e57ebd0c3012b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e6d1e10fb34daea60ef72f995ff880":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be32063f485f44b89f4d0fe873bda711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43e85aca7957440bb0a23004949cf980":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d088cd4c0f4cd285b793d6b3cafabd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_552ac2acad8b4c08ae9cfdbf8ee82c1e","IPY_MODEL_74c3f2eaaa0942669baa07d3e86ba1d4","IPY_MODEL_96c978bef8c8444cb943d3964b352576"],"layout":"IPY_MODEL_1b46434bcdb640e18b840253b060d028"}},"552ac2acad8b4c08ae9cfdbf8ee82c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cc511d55e534abb987005861fab0fb3","placeholder":"​","style":"IPY_MODEL_8cbb326c1eca49f3a69043381201e183","value":"Downloading: 100%"}},"74c3f2eaaa0942669baa07d3e86ba1d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c9f4490eed142c3abd97cf773ed2e1d","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4406d252e3b34f83b66f0646ae4f1cd2","value":1355863}},"96c978bef8c8444cb943d3964b352576":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebbe135349954ca4a5b6c22964a3289e","placeholder":"​","style":"IPY_MODEL_4f5a81d328cb48d4bbecf02bd406da82","value":" 1.36M/1.36M [00:00&lt;00:00, 1.57MB/s]"}},"1b46434bcdb640e18b840253b060d028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc511d55e534abb987005861fab0fb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cbb326c1eca49f3a69043381201e183":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c9f4490eed142c3abd97cf773ed2e1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4406d252e3b34f83b66f0646ae4f1cd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebbe135349954ca4a5b6c22964a3289e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f5a81d328cb48d4bbecf02bd406da82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d99499198a44499eb6549216807d9aaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe1f0f11decc428cb5b38ed5fb17f194","IPY_MODEL_97268edb88d84c4f93268ff7fa7bb857","IPY_MODEL_8b42527ee51448d887c05eb0d17ead60"],"layout":"IPY_MODEL_174e61c69b82448d9dd70c068f186e17"}},"fe1f0f11decc428cb5b38ed5fb17f194":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b1879047cea456ab42fbc93a3c6866e","placeholder":"​","style":"IPY_MODEL_873720057bc7476cae88372c72c058ed","value":"Downloading: 100%"}},"97268edb88d84c4f93268ff7fa7bb857":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_64a8ce93220e4910ae7bbb633f635b1d","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f532932f2b0146c2816a4bd7ca78dedb","value":501200538}},"8b42527ee51448d887c05eb0d17ead60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0616c64aa21d490ea4947208ffc11512","placeholder":"​","style":"IPY_MODEL_090a00d5ac4d463f80d2be8b0fa5634c","value":" 501M/501M [00:11&lt;00:00, 57.8MB/s]"}},"174e61c69b82448d9dd70c068f186e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b1879047cea456ab42fbc93a3c6866e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"873720057bc7476cae88372c72c058ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64a8ce93220e4910ae7bbb633f635b1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f532932f2b0146c2816a4bd7ca78dedb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0616c64aa21d490ea4947208ffc11512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"090a00d5ac4d463f80d2be8b0fa5634c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eae3a20aca844cd68ce455e7386731f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5f74bab89b94910a2122bf2dd6e1011","IPY_MODEL_0e47da26353644d1b33497f8dc1a851d","IPY_MODEL_8488098f91e44fbf837393f62f27b2c4"],"layout":"IPY_MODEL_cc792a547b3f48258a080e8b98dd467c"}},"e5f74bab89b94910a2122bf2dd6e1011":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bb2bed077fb4d54a0f2186eb6c009d8","placeholder":"​","style":"IPY_MODEL_9d36919a47314b3795eadb7bb41345df","value":"Downloading builder script: "}},"0e47da26353644d1b33497f8dc1a851d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76f8c7c755e5431db56ab4cd1010caef","max":1652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_232777434a784470ab45c155429da15e","value":1652}},"8488098f91e44fbf837393f62f27b2c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ec5109d5e334068b29f8238c2265a7a","placeholder":"​","style":"IPY_MODEL_3b12a6789fc4473fa588231f68e64bad","value":" 4.21k/? [00:00&lt;00:00, 132kB/s]"}},"cc792a547b3f48258a080e8b98dd467c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bb2bed077fb4d54a0f2186eb6c009d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d36919a47314b3795eadb7bb41345df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76f8c7c755e5431db56ab4cd1010caef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"232777434a784470ab45c155429da15e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ec5109d5e334068b29f8238c2265a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b12a6789fc4473fa588231f68e64bad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e553dee82c314ecb902c83b6fdcb5320":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ffbd5847fde4074bb592094209c86d2","IPY_MODEL_d52d5a4f08a24129b538257138abe308","IPY_MODEL_141aed2685dd4e93859b5ed0e76809bc"],"layout":"IPY_MODEL_ddfb8523f8164a60b9c6b6168f40fdbb"}},"8ffbd5847fde4074bb592094209c86d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52a93cc120214b56b293ba11630bf62e","placeholder":"​","style":"IPY_MODEL_4e15e9c24b8344eea8c645f5d4e1e74b","value":"Downloading builder script: "}},"d52d5a4f08a24129b538257138abe308":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6a2b6fe8f149a5b581b517d607dd0d","max":2318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7dc9477be5d45bc8b90ae32f682835c","value":2318}},"141aed2685dd4e93859b5ed0e76809bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae085eae263c45cbb1ff49c3c126ef56","placeholder":"​","style":"IPY_MODEL_c09ef62f9d36468ca62b592592783e01","value":" 6.50k/? [00:00&lt;00:00, 124kB/s]"}},"ddfb8523f8164a60b9c6b6168f40fdbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52a93cc120214b56b293ba11630bf62e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e15e9c24b8344eea8c645f5d4e1e74b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd6a2b6fe8f149a5b581b517d607dd0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7dc9477be5d45bc8b90ae32f682835c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae085eae263c45cbb1ff49c3c126ef56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c09ef62f9d36468ca62b592592783e01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87983496340a4dc59a57c384bc3e84eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_755f025545c84fd497976b3b5d1d2551","IPY_MODEL_8bba6f085f1242ab876670a65b8f2781","IPY_MODEL_100f6004ea884232ab8f7f106742b4c5"],"layout":"IPY_MODEL_4245f2e72d17432bab955b160d786d37"}},"755f025545c84fd497976b3b5d1d2551":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58d6d274571b47ef9f6f7672e05d9a94","placeholder":"​","style":"IPY_MODEL_5222919efae84f32a338671bdaa823aa","value":"  4%"}},"8bba6f085f1242ab876670a65b8f2781":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_99de7d09885a460a8a0c6d8f73d2c7fc","max":28200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1424c7421a94835ad9747a994785a0b","value":1127}},"100f6004ea884232ab8f7f106742b4c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_686c86ff6595452780b0e0b3e26966ad","placeholder":"​","style":"IPY_MODEL_c6bd8db4813745d7b6467eab907ac751","value":" 1127/28200 [32:56&lt;13:01:06,  1.73s/it]"}},"4245f2e72d17432bab955b160d786d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d6d274571b47ef9f6f7672e05d9a94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5222919efae84f32a338671bdaa823aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99de7d09885a460a8a0c6d8f73d2c7fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1424c7421a94835ad9747a994785a0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"686c86ff6595452780b0e0b3e26966ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6bd8db4813745d7b6467eab907ac751":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}